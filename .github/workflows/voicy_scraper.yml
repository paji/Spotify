name: Voicy URL Scraper

on:
  schedule:
    - cron: '31 * * * *'  # 毎時31分に実行
  workflow_dispatch:  # 手動実行用

# 明示的に権限を設定
permissions:
  contents: write
  actions: write

jobs:
  voicy-url-scraper:
    runs-on: ubuntu-latest
    
    steps:
      - name: チェックアウト
        uses: actions/checkout@v4
      
      - name: Python 3.10 セットアップ
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: Chrome ブラウザのセットアップ
        uses: browser-actions/setup-chrome@latest
      
      - name: 依存関係のインストール
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 selenium webdriver-manager tqdm
      
      - name: Voicy URL スクレイピングスクリプト作成
        run: |
          cat > voicy_url_scraper.py << 'EOF'
          import os
          import re
          import json
          import time
          import random
          from datetime import datetime, timedelta
          from bs4 import BeautifulSoup
          import traceback
          from tqdm import tqdm
          from selenium import webdriver
          from selenium.webdriver.chrome.options import Options
          from selenium.webdriver.chrome.service import Service
          from selenium.webdriver.common.by import By
          from selenium.webdriver.support.ui import WebDriverWait
          from selenium.webdriver.support import expected_conditions as EC
          from selenium.common.exceptions import TimeoutException, NoSuchElementException, StaleElementReferenceException
          from webdriver_manager.chrome import ChromeDriverManager

          # Voicyチャンネル情報
          CHANNEL_ID = "2834"  # 裏・パジちゃんねる
          CHANNEL_URL = f"https://voicy.jp/channel/{CHANNEL_ID}/all"  # チャンネル全エピソードページ

          # 出力ファイル設定
          OUTPUT_DIR = "output"
          OUTPUT_JSON = os.path.join(OUTPUT_DIR, "voicy_episodes.json")
          OUTPUT_URLS_ONLY = os.path.join(OUTPUT_DIR, "voicy_urls_only.json")
          DEBUG_DIR = os.path.join(OUTPUT_DIR, "debug")

          # スクレイピング設定
          MAX_RETRIES = 5  # 最大リトライ回数
          SCROLL_PAUSE_TIME = 1  # スクロール間の待機時間（秒）
          MAX_SCROLL_ATTEMPTS = 2  # 最大スクロール試行回数（約20件のエピソードを取得するため）
          TARGET_EPISODES = 20  # 目標エピソード数

          def setup_directories():
              """必要なディレクトリを作成"""
              for directory in [OUTPUT_DIR, DEBUG_DIR]:
                  os.makedirs(directory, exist_ok=True)
                  print(f"ディレクトリを確認/作成しました: {directory}")

          def random_sleep(min_seconds=0.5, max_seconds=1.5):
              """ランダムな時間スリープする（サーバー負荷軽減のため）"""
              sleep_time = random.uniform(min_seconds, max_seconds)
              time.sleep(sleep_time)
              return sleep_time

          def load_existing_episodes():
              """
              既存のJSONファイルからエピソード情報を読み込む関数
              
              Returns:
                  tuple: (既存のエピソードリスト, 既存のエピソードIDのセット)
              """
              existing_episodes = []
              existing_episode_ids = set()
              
              if os.path.exists(OUTPUT_JSON):
                  try:
                      with open(OUTPUT_JSON, 'r', encoding='utf-8') as f:
                          existing_episodes = json.load(f)
                          
                      # エピソードIDのセットを作成
                      for episode in existing_episodes:
                          if "id" in episode:
                              existing_episode_ids.add(episode["id"])
                      
                      print(f"既存のJSONファイルから {len(existing_episodes)} 件のエピソード情報を読み込みました。")
                      print(f"重複チェック用に {len(existing_episode_ids)} 件のエピソードIDを準備しました。")
                  except Exception as e:
                      print(f"既存のJSONファイルの読み込み中にエラーが発生しました: {e}")
              else:
                  print(f"既存のJSONファイル {OUTPUT_JSON} が見つかりませんでした。新規作成します。")
              
              return existing_episodes, existing_episode_ids

          def parse_date_from_element(parent):
              """
              親要素からtimeタグやdata属性を使用して日付情報を取得する関数
              
              Args:
                  parent: 親要素（Seleniumの要素オブジェクト）
                  
              Returns:
                  tuple: (datetime オブジェクト, 日付文字列)
              """
              episode_date = None
              date_str = None
              
              try:
                  # 1. timeタグを優先的に探す
                  try:
                      time_element = parent.find_element(By.CSS_SELECTOR, "time")
                      
                      # data-timestamp属性を確認（Unixタイムスタンプ）
                      timestamp = time_element.get_attribute("data-timestamp")
                      if timestamp and timestamp.isdigit():
                          # Unixタイムスタンプを日時に変換
                          episode_date = datetime.fromtimestamp(int(timestamp))
                          date_str = time_element.text.strip()
                          return episode_date, date_str
                      
                      # datetime属性を確認（ISO形式の日時）
                      datetime_attr = time_element.get_attribute("datetime")
                      if datetime_attr:
                          try:
                              # ISO形式の日時を解析
                              episode_date = datetime.fromisoformat(datetime_attr.replace('Z', '+00:00'))
                              date_str = time_element.text.strip()
                              return episode_date, date_str
                          except ValueError:
                              pass
                      
                      # timeタグのテキストを取得
                      date_str = time_element.text.strip()
                  except:
                      # timeタグが見つからない場合は他の日付要素を探す
                      try:
                          date_element = parent.find_element(By.CSS_SELECTOR, ".date, .episode-date")
                          date_str = date_element.text.strip()
                      except:
                          date_str = None
              except:
                  date_str = None
              
              # 日付文字列が取得できた場合は解析を試みる
              if date_str:
                  episode_date = parse_date_string(date_str)
              
              return episode_date, date_str

          def parse_date_string(date_str):
              """
              日付文字列を解析してdatetimeオブジェクトに変換する関数
              
              Args:
                  date_str: 日付を表す文字列
                  
              Returns:
                  datetime: 解析された日時オブジェクト、解析失敗時はNone
              """
              if not date_str:
                  return None
              
              # 現在の日時を取得（相対日付計算用）
              now = datetime.now()
              
              try:
                  # 1. 相対日付の解析（例: 3日前、1週間前、2時間前）
                  relative_match = re.search(r'(\d+)\s*(時間|日|週間|ヶ月|カ月|ヵ月|か月|年)\s*前', date_str)
                  if relative_match:
                      value = int(relative_match.group(1))
                      unit = relative_match.group(2)
                      
                      if unit == '時間':
                          return now - timedelta(hours=value)
                      elif unit == '日':
                          return now - timedelta(days=value)
                      elif unit == '週間':
                          return now - timedelta(weeks=value)
                      elif unit in ['ヶ月', 'カ月', 'ヵ月', 'か月']:
                          # 月は正確な日数がないので近似値を使用
                          return now - timedelta(days=value * 30)
                      elif unit == '年':
                          # 年も近似値を使用
                          return now - timedelta(days=value * 365)
                  
                  # 2. 「今日」「昨日」「一昨日」などの特殊な相対日付
                  if '今日' in date_str:
                      return now
                  elif '昨日' in date_str:
                      return now - timedelta(days=1)
                  elif '一昨日' in date_str or '2日前' in date_str:
                      return now - timedelta(days=2)
                  
                  # 3. 日付フォーマットのパターンを試行
                  date_formats = [
                      # 年月日 時分 形式
                      "%Y年%m月%d日 %H時%M分",
                      "%Y年%m月%d日 %H:%M",
                      "%Y/%m/%d %H:%M",
                      "%Y-%m-%d %H:%M",
                      # 年月日のみ
                      "%Y年%m月%d日",
                      "%Y/%m/%d",
                      "%Y-%m-%d",
                      # 月日 時分 形式
                      "%m月%d日 %H時%M分",
                      "%m月%d日 %H:%M",
                      "%m/%d %H:%M",
                      # 月日のみ
                      "%m月%d日",
                      "%m/%d"
                  ]
                  
                  for date_format in date_formats:
                      try:
                          # 時間情報を含まないフォーマットで年が省略されている場合
                          if (len(date_format.split()) > 0 and "年" not in date_format.split()[0] and "/" not in date_format.split()[0] and "-" not in date_format.split()[0]) and \
                             (len(date_str.split()) > 0 and "年" not in date_str.split()[0] and "/" not in date_str.split()[0] and "-" not in date_str.split()[0]):
                              # 現在の年を使用
                              parsed_date = datetime.strptime(date_str, date_format)
                              return parsed_date.replace(year=now.year)
                          
                          # 完全な日付
                          return datetime.strptime(date_str, date_format)
                      except (ValueError, IndexError):
                          continue
              
              except Exception as e:
                  print(f"日付の解析中にエラーが発生しました: {e}")
              
              # 解析できなかった場合はNoneを返す
              return None

          def get_episodes_info_selenium():
              """
              Seleniumを使用してVoicyチャンネルのエピソード情報を取得する関数
              
              Returns:
                  list: エピソード情報のリスト
              """
              print(f"Voicyチャンネル {CHANNEL_URL} からエピソード情報を取得します...")
              
              # 既存のエピソード情報を読み込む
              existing_episodes, existing_episode_ids = load_existing_episodes()
              
              episodes = []
              episode_ids_seen = existing_episode_ids.copy()  # 既存のエピソードIDをコピー
              retry_count = 0
              
              print(f"重複チェック用に {len(episode_ids_seen)} 件の既存エピソードIDを読み込みました。")
              
              try:
                  # Chromeオプションの設定
                  chrome_options = Options()
                  chrome_options.add_argument("--headless")
                  chrome_options.add_argument("--no-sandbox")
                  chrome_options.add_argument("--disable-dev-shm-usage")
                  chrome_options.add_argument("--disable-gpu")
                  chrome_options.add_argument("--window-size=1920,1080")
                  chrome_options.add_argument("--disable-notifications")
                  chrome_options.add_argument("--disable-extensions")
                  chrome_options.add_argument("--disable-infobars")
                  
                  # WebDriverの初期化
                  service = Service(ChromeDriverManager().install())
                  driver = webdriver.Chrome(service=service, options=chrome_options)
                  
                  # タイムアウト設定
                  driver.set_page_load_timeout(60)
                  
                  # 最初のページを読み込み
                  driver.get(CHANNEL_URL)
                  
                  # ページが完全に読み込まれるまで待機
                  WebDriverWait(driver, 30).until(
                      EC.presence_of_element_located((By.CSS_SELECTOR, "a[href*='/channel/'][href*='/']"))
                  )
                  
                  # デバッグ用にHTMLを保存
                  with open(os.path.join(DEBUG_DIR, "initial_page.html"), "w", encoding="utf-8") as f:
                      f.write(driver.page_source)
                  
                  # プログレスバーの初期化（目標エピソード数: 2200）
                  progress = tqdm(total=TARGET_EPISODES, desc="エピソード取得")
                  
                  # オートページローディングのためのスクロール処理
                  scroll_count = 0
                  no_new_episodes_count = 0
                  max_no_new_episodes = 5  # 新しいエピソードが見つからない最大回数
                  
                  while scroll_count < MAX_SCROLL_ATTEMPTS and len(episodes) < TARGET_EPISODES:
                      # 現在のエピソード数を記録
                      current_episode_count = len(episodes)
                      
                      # ページの最下部までスクロール
                      driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                      random_sleep(SCROLL_PAUSE_TIME, SCROLL_PAUSE_TIME + 1)
                      
                      # 新しいコンテンツが読み込まれるのを待機
                      try:
                          WebDriverWait(driver, 5).until(
                              lambda d: d.execute_script("return document.body.scrollHeight") > driver.execute_script("return window.innerHeight + window.pageYOffset")
                          )
                      except:
                          pass
                      
                      # エピソードリンクを取得
                      episode_links = driver.find_elements(By.CSS_SELECTOR, "a[href*='/channel/'][href*='/']")
                      
                      # エピソード情報を抽出
                      for link in episode_links:
                          try:
                              href = link.get_attribute("href")
                              # エピソードURLのパターンをチェック
                              match = re.search(r'/channel/\d+/(\d+)$', href)
                              if match:
                                  episode_id = match.group(1)
                                  if episode_id not in episode_ids_seen:
                                      episode_ids_seen.add(episode_id)
                                      
                                      # 親要素を取得してタイトルと日付を探す
                                      parent = link
                                      title_element = None
                                      
                                      for _ in range(5):  # 最大5階層まで親を辿る
                                          try:
                                              parent = parent.find_element(By.XPATH, "..")
                                              try:
                                                  title_element = parent.find_element(By.CSS_SELECTOR, "h2, h3, .title, .episode-title")
                                                  if title_element:
                                                      break
                                              except:
                                                  pass
                                          except:
                                              break
                                      
                                      # タイトルを取得（見つからない場合はデフォルト値を使用）
                                      title = title_element.text if title_element else f"エピソード {episode_id}"
                                      
                                      # 日付要素を探す
                                      episode_date = None
                                      date_str = None

                                      # 改良された日付解析関数を使用
                                      episode_date, date_str = parse_date_from_element(parent)

                                      # 日付が解析できなかった場合は現在の日付を使用
                                      if episode_date is None:
                                          print(f"日付を解析できませんでした: {date_str}")
                                          episode_date = datetime.now()

                                      # 日付と時間を含むフォーマットで保存
                                      date_str = episode_date.strftime("%Y-%m-%d %H:%M:%S")
                                      
                                      # エピソード情報を追加
                                      episodes.append({
                                          "id": episode_id,
                                          "title": title,
                                          "date": date_str,
                                          "url": href
                                      })
                                      
                                      # プログレスバーを更新
                                      progress.update(1)
                                      progress.set_description(f"エピソード取得中 ({len(episodes)}/{TARGET_EPISODES})")
                                      
                                      # 定期的に中間結果を保存（100件ごと）
                                      if len(episodes) % 100 == 0:
                                          save_episodes_to_json(existing_episodes + episodes, is_temp=True)
                                          print(f"現在 {len(episodes)} 件の新規エピソードを取得しました。")
                                  else:
                                      # 既に見たエピソードの場合はスキップ
                                      print(f"エピソードID {episode_id} は既に存在するためスキップします。")
                          except StaleElementReferenceException:
                              print("要素が古くなりました。スキップします。")
                              continue
                          except Exception as e:
                              print(f"エピソード情報の抽出中にエラーが発生しました: {e}")
                              continue
                      
                      # スクロールカウントを増やす
                      scroll_count += 1
                      
                      # 新しいエピソードが追加されたかチェック
                      if len(episodes) > current_episode_count:
                          no_new_episodes_count = 0  # リセット
                      else:
                          no_new_episodes_count += 1
                          print(f"新しいエピソードが見つかりませんでした。({no_new_episodes_count}/{max_no_new_episodes})")
                          
                          if no_new_episodes_count >= max_no_new_episodes:
                              print(f"連続 {max_no_new_episodes} 回新しいエピソードが見つかりませんでした。スクレイピングを終了します。")
                              break
                      
                      # 100スクロールごとにステータス表示
                      if scroll_count % 100 == 0:
                          print(f"スクロール回数: {scroll_count}, 取得エピソード数: {len(episodes)}")
                          
                          # ページの高さを取得して表示（デバッグ用）
                          page_height = driver.execute_script("return document.body.scrollHeight")
                          window_height = driver.execute_script("return window.innerHeight")
                          scroll_position = driver.execute_script("return window.pageYOffset")
                          print(f"ページ高さ: {page_height}, ウィンドウ高さ: {window_height}, スクロール位置: {scroll_position}")
                          
                          # 現在のHTMLを保存（デバッグ用）
                          with open(os.path.join(DEBUG_DIR, f"scroll_{scroll_count}.html"), "w", encoding="utf-8") as f:
                              f.write(driver.page_source)
                  
                  # プログレスバーを閉じる
                  progress.close()
                  
                  print(f"合計 {len(episodes)} 件の新規エピソードを取得しました。")
                  print(f"スクロール回数: {scroll_count}")
                  
              except Exception as e:
                  print(f"エピソード情報の取得中にエラーが発生しました: {e}")
                  traceback.print_exc()
              finally:
                  if 'driver' in locals() and driver:
                      driver.quit()
              
              # 既存のエピソードと新規エピソードを結合して返す
              return existing_episodes + episodes

          def save_episodes_to_json(episodes, is_temp=False):
              """
              エピソード情報をJSONファイルに保存する関数
              
              Args:
                  episodes: エピソード情報のリスト
                  is_temp: 一時ファイルとして保存するかどうか
              """
              try:
                  output_path = OUTPUT_JSON
                  if is_temp:
                      output_path = os.path.join(OUTPUT_DIR, f"voicy_episodes_temp_{len(episodes)}.json")
                  
                  with open(output_path, 'w', encoding='utf-8') as f:
                      json.dump(episodes, f, ensure_ascii=False, indent=2)
                  
                  if is_temp:
                      print(f"一時エピソード情報をJSONファイルに保存しました: {output_path}")
                  else:
                      print(f"エピソード情報をJSONファイルに保存しました: {output_path}")
              except Exception as e:
                  print(f"JSONファイルの保存中にエラーが発生しました: {e}")

          def save_urls_only_to_json(episodes):
              """
              URLのみのリストをJSONファイルに保存する関数
              
              Args:
                  episodes: エピソード情報のリスト
              """
              try:
                  urls_only = [episode["url"] for episode in episodes]
                  with open(OUTPUT_URLS_ONLY, 'w', encoding='utf-8') as f:
                      json.dump(urls_only, f, ensure_ascii=False, indent=2)
                  print(f"URLのみのリストをJSONファイルに保存しました: {OUTPUT_URLS_ONLY}")
              except Exception as e:
                  print(f"URLのみのリストの保存中にエラーが発生しました: {e}")

          def main():
              """メイン関数"""
              print("Voicy URL スクレイパーを開始します...")
              start_time = time.time()
              
              # ディレクトリ設定
              setup_directories()
              
              # エピソード情報を取得
              episodes = get_episodes_info_selenium()
              
              # エピソード情報をJSONファイルに保存
              save_episodes_to_json(episodes)
              
              # URLのみのリストも作成
              save_urls_only_to_json(episodes)
              
              end_time = time.time()
              elapsed_time = end_time - start_time
              hours, remainder = divmod(elapsed_time, 3600)
              minutes, seconds = divmod(remainder, 60)
              
              print(f"処理が完了しました。実行時間: {int(hours)}時間 {int(minutes)}分 {int(seconds)}秒")
              print(f"取得したエピソード数: {len(episodes)}")

          if __name__ == "__main__":
              main()
          EOF
      
      - name: スクリプトを実行
        run: python voicy_url_scraper.py
      
      - name: 結果をアップロード
        uses: actions/upload-artifact@v4
        with:
          name: voicy-episodes-json
          path: |
            output/voicy_episodes.json
            output/voicy_urls_only.json
      
      - name: 結果をコミット
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add output/voicy_episodes.json output/voicy_urls_only.json
          git commit -m "Update Voicy episodes JSON" || echo "No changes to commit"
          git push
