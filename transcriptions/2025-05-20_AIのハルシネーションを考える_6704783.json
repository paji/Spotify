{
  "title": "AIのハルシネーションを考える",
  "date": "2025-05-20",
  "filename": "2025-05-20_AIのハルシネーションを考える_6704783.mp3",
  "transcription": "裏っ端チャンネル 今回のテーマは AI のハルシネーションを考えるという話をしていきたいと思います2025年に入って AI の進化が止まらないというところでかなりこう性格性も高まってきているものの一部やはりハルシネーションを起こしていてこれもっともらしく結構断言して AI が回答しているけれどもこれ全然専門家から言わせれば違う答えですよというご指摘を受けることもちょっと増えてきています正当率という意味ではだんだんと年々進化しているもののやっぱり領域によってはまだ事前に学習できていないような情報知識というのがまだまだたくさんあってすごいすごいとこう AI がもてはやされているとそれにちょっと反発したくなるような気持ちもちょっと相まっていやまぁハルシネーションが起こるからあんま手放しでこう信じない方がいいですよというある意味での優しいアドバイスを受けるんですよねAI にしても人間にしても様々な相談事とか問題解決を図るという時に100%全副の信頼を置いてその回答とか解決法を信じるというのはまあそもそもインターネットに情報が溢れ出してからそこに載っている情報の真偽というのはハルシネーションという言葉ではなかったものの常に怪しい情報なのか信じていい情報なのかというのは結構鍛えられてきた感じですよねそれを人間の話し言葉のように AI が回答してくれるのでますますこの納得してしまう気持ちというのが確かに AI のハルシネーションは気をつけなければいけないというのはその通りなんだと思うんですよねただ私これ思うのはもうすでにこれ現状の人間よりは信じてもいいかなというレベルにはトップの AI ツールに関しては論文を読み込ませたりとかその時点での最新の web リサーチをかけていたりとある種一時情報とかかなり信頼できるようなサイトをその瞬間につどつど反乱しているということを考えると曖昧な記憶に頼る人間の回答なんかよりは平均的には正しい回答を返しているというふうに見なしてもいいかなというぐらいにはAI もかなり賢く正しくなってきているんですよねさらに言えば AI のハルシネーションがどうしても気になるということであれば自分自身でこれが正しいと思えるデータを AI に mcp 経由とかそもそも md ファイルとか csv ファイルでちゃんと環境を整備した上で突っ込んでおくとか論文しか参照しないよというようなオプション機能を設ければいわゆる今人間の界隈の中でこれは正しいと思えるような情報だけを抜粋してAI がその答えを人間らしく返してくれるという状態には持ち込めるんですよねあらかじめプリセットされていたようなデータを用いた場合にある種ネット上のノイズのようなものが混ざって全然こう検討外れのハルシネーションを起こすところは今は人間側が手当てするということで厳格なデータベースを構築さえしてあげればいいということでもあるんですがただまぁこれもちょっと考え方次第かなと思うんですよね領域ごとに例えば数学の世界で言えば確実に1たす1が2であるという正解と不正解というのが存在していますがそもそもこういったシンプルな回答でそれ以外が間違っているというような問題とか相談ごとっていうのは世の中にはそこまで多くなくて結構こうポジションによっては正解になったり不正解になるケースっていうのはありますよねビジネスシーンにおいては短期的に売り上げが上がるからとプロモーションを連発していくことで短期的には売り上げが大きく伸ばせたとしてもプロモーションを連発することでブランディング価値が下がったりとかユーザーがそれに慣れすぎて後々中長期的には苦しむといったことが起こるように何かの事象に対してそれが正解か不正解かそれがハルシネーションを起こしているのかどうかというのはもしかしたら専門家の中にもポジションをどう取っているかによってあえてこうハルシネーションといってネガティブキャンペーンを張りたいというケースもあり得るわけですね人間はここら辺の政治的な動き方とか感情的な機微というのが非常に賢い動物であるということも忘れてはならないんだと思うんですねもう一つ結構ハルシネーションの問題の時に気になるのは例えば歴史的にこれが事実だと思われているような重要なファクトが後々研究をもっと深掘っていったら全然真逆の答えになってしまって事実が完全に書き換えられるといったことっていうのはよくあることですよね一時情報むしろゼロ時情報にアタックできていない時に本当にその情報が正しいのかというのは一旦現時点においてはほぼ正しいでしょうというぐらいの角度でしかなくてそれは非常にオーソリティの高い論文とかあるいは信頼できる専門家たちによってこれからもAIが自律的にそうしたある種人間が考える信用できる一時情報書き換え次の一時情報にアクセスしてハルシネーション率を下げてくれると考えるならば今後どこまでAIのハルシネーションがというこのことさえもAI時代の例名機的な昔話になるのかなというふうに思いましたということで今日はここまでここまでバイバイバイバイ"
}